---
title: "Franchise Distributions"
author: "Will Jones"
date: "April 1, 2015"
output:
  html_document:
    keep_md: yes
---

```{r, echo=FALSE, warning=FALSE}
# Load all the packages
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(ggmap))
suppressPackageStartupMessages(library(doParallel))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(rgdal))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(jsonlite))
suppressPackageStartupMessages(library(RCurl))


# Set up parallel processing
cpuCount <- detectCores() #From the parallel package
registerDoParallel(cores=cpuCount-1) #Don't take all cores.
```

This project examines correlations between the number of Starbuck's locations
in an area with demographics information---such as ethnic makeup, median income,
poverty level. For the locations, this project examines census tracts in Los
Angeles County.

Census data is provided by the 2010 census for estimates of population and
ethnic makeup, while we use ACS five-year estimates for median income and
poverty level.

```{r, echo=FALSE}
# Get 2010 census data
la.census <- read.csv('LA_census_2010.csv', 
                      colClasses=c(rep("character", 10), 
                                   rep("numeric", 62))) %>% 
                        tbl_df()
la.census %<>% 
  # select only Los Angeles County
  filter(Geo_COUNTY == '037') %>%
  rename(population = SE_T001_001,
         white = SE_T054_002)

# Get income census data (from 5-year estimates)
la.income <- read.csv('LA_income.csv',
                      colClasses=c(rep('character', 5),
                                   rep('factor', 15),
                                   rep('numeric', 82))) %>%
  tbl_df() %>%
  filter(Geo_COUNTY == '037') %>%
  rename(median.income = SE_T057_001,
         pop.poverty = SE_T118_002)

# Combine the two data frames
la.census %<>% left_join(la.income, by='Geo_FIPS') %>%
  select(Geo_FIPS, population, white, median.income, pop.poverty)

la.census$Geo_FIPS %<>% as.character()

# Convert white and poverty to rates in percents
la.census %<>%
  mutate(white = white / population * 100,
         rate.poverty = pop.poverty / population * 100)
```

Here are some histograms of the basic demographic data:

```{r, echo=FALSE}
par(mfrow=c(2,2))
hist(la.census$white, main="Percentage of Population that is White")
hist(la.census$rate.poverty, main="Percentage of Population Below Poverty Level")
hist(la.census$median.income, main="Median Income")
hist(la.census$population, main="Population")
```





```{r, echo=FALSE, warning=FALSE}
# Number of census tracts to sample
n <- 2
search.text <- 'Starbucks Coffee'

# Loading the shape file
# LA.shapefile <- readOGR(dsn="los_angeles/", 
#                         layer="eGIS_Demographic.EGIS", 
#                        verbose=FALSE) %>%
#  spTransform(CRS("+proj=longlat +ellps=WGS84"))

# LA.data <- LA.shapefile@data %>% tbl_df()

# I wasn't able to get this to work on my R installation, but Albert Kim was
# able to do so and save it as a data frame.
# LA.map <- fortify(LA.shapefile, region='GEOID10') %>% tbl_df()
load('LA.RData') # saved as LA.map

# Subset shapefile to tracts we want to look at
LA.map %<>% 
  inner_join(la.census, by=c('id' = 'Geo_FIPS')) %>%
  filter(lat > 33.5)

# Add in data giving the geographic centers of the 

# Create a sample of FIPS to look at
LA.sample <- la.census %>%
  sample_n(n) %>%
  .$Geo_FIPS

LA.map %<>% mutate(in.sample = id %in% LA.sample)

# Plot which tracts we are sampling
ggplot(LA.map, aes(x=long, y=lat, group=group)) +
  geom_polygon(aes(fill=in.sample )) +
  coord_map() +
  theme_bw()

```

Now that we have a selection of census tracts to examine, we need to find how
many Starbucks locations are nearby each. We can start by constructing a table
of locations, queried using a radar search centered at the geographic center of
the sampled census tracts.

```{r, warning=FALSE}
# Get the geographic centers of each of the polygons
centers <- LA.map %>%
  group_by(id) %>%
  summarise(center.x = mean(long),
            center.y = mean(lat))

LA.map %<>% left_join(centers, by=c('id' = 'id'))

ggplot(LA.map) +
  geom_polygon(aes(fill=in.sample,
                   x=long, y=lat, group=group)) +
  geom_point(aes(x = center.x, y = center.y)) + 
  coord_map() +
  theme_bw()
```

These geographic centers are not perfect. Tracts who have borders that do not
have evenly distributed vertices on their edges (such as ones where one side is
particularly jagged) tend to have centers that are too close to the edge. For
most of the median and small census tracts, they will work just fine.

```{r}
# Define function to get nearby locations
getLocations <- function(x, y, query, radius=10000) {
  # Uses Google Places to find all locations near a place.
  # Remember we want to over shoot, and then count those that
  # are actually near the borders of the 
  #
  # Args: 
  #  x: the lattitude of the center from which to search
  #  y: the longitude of the center from which to search
  #  radius: the radius of the search, in meters
  #  query: the name of the franchise to search for
  #
  # Returns:
  #  A dataframe of locations.
  
  # First, construct the query URL
  gplaces.key <- readLines('Google_API_key.txt')
  url <- 'https://maps.googleapis.com/maps/api/place/radarsearch/json?'
  url %<>% paste('key=', gplaces.key, '&', sep='')
  url %<>% paste('location=', as.character(x), ',',
                 as.character(y), '&', sep='')
  url %<>% paste('radius=', as.character(radius), '&', sep='')
  query %<>% str_replace(' ', '+')
  url %<>% paste('keyword=', query, sep='')
  
  data <- url %>% getURL() %>% fromJSON()

  
  data %<>% .$results %>% as.data.frame()
  
  output <- data_frame(place_id = data$place_id,
                       lat = data$geometry$location$lat,
                       long = data$geometry$location$lng)
  return(output) 
}

test <- getLocations(34.0429419, -118.2657636, 'starbucks coffee')

locations <- data_frame(place_id = character(),
                        lat = numeric(),
                        long = numeric())

rows <- centers %>% filter(id %in% LA.sample)

for (i in 1:nrow(rows)) {
  place <- rows[i,]
  new.locations <- getLocations(place$center.y,
                                place$center.x,
                                search.text)
  locations %<>% union(new.locations)
}
  

ggplot() +
  geom_polygon(data = LA.map,
               aes(fill=in.sample,
                   x=long, y=lat, group=group)) +
  geom_point(data = locations,
             aes(x = long, y = lat)) + 
  coord_map() +
  theme_bw()

```





```{r}
countLocations <- function(polygon, locations, radius=5000) {
  # Counts the number of locations that are either inside the polygon, or are 
  # within the given radius of a border.
  #
  # Args:
  #  polygon: a dataframe of edges of the polygon
  #  locations: a dataframe of the locations, which is returned by getLocations
  #
  # Returns: 
  #  An integer indicating how many locations are near the polygon
  
  # First, check if the point is actually inside the polygon
  output <- point.in.polygon(locations$lat, locations$long, 
                   polygon$lat, polygon$long)
  
  # If that doesn't work, check whether they are within a certain radius of the
  # edges of of polygon.
  
  
}
```

