---
title: "Franchise Distributions"
author: "Will Jones"
date: "April 1, 2015"
output:
  html_document:
    keep_md: yes
---

```{r, echo=FALSE, warning=FALSE}
# Load all the packages
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(ggmap))
suppressPackageStartupMessages(library(doParallel))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(rgdal))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(jsonlite))
suppressPackageStartupMessages(library(RCurl))
suppressPackageStartupMessages(library(rgeos))



# Set up parallel processing
cpuCount <- detectCores() #From the parallel package
registerDoParallel(cores=cpuCount-1) #Don't take all cores.
```

This project examines correlations between the number of Starbuck's locations
in an area with demographics information---such as ethnic makeup, median income,
poverty level. For the locations, this project examines census tracts in Los
Angeles County.

Census data is provided by the 2010 census for estimates of population and
ethnic makeup, while we use ACS five-year estimates for median income and
poverty level.

```{r, echo=FALSE}
# Get 2010 census data
la.census <- read.csv('LA_census_2010.csv', 
                      colClasses=c(rep("character", 10), 
                                   rep("numeric", 62))) %>% 
                        tbl_df()
la.census %<>% 
  # select only Los Angeles County
  filter(Geo_COUNTY == '037') %>%
  rename(population = SE_T001_001,
         white = SE_T054_002)

# Get income census data (from 5-year estimates)
la.income <- read.csv('LA_income.csv',
                      colClasses=c(rep('character', 5),
                                   rep('factor', 15),
                                   rep('numeric', 82))) %>%
  tbl_df() %>%
  filter(Geo_COUNTY == '037') %>%
  rename(median.income = SE_T057_001,
         pop.poverty = SE_T118_002)

# Combine the two data frames
la.census %<>% left_join(la.income, by='Geo_FIPS') %>%
  select(Geo_FIPS, population, white, median.income, pop.poverty)

la.census$Geo_FIPS %<>% as.character()

# Convert white and poverty to rates in percents
la.census %<>%
  mutate(white = white / population * 100,
         rate.poverty = pop.poverty / population * 100)
```

Here are some histograms of the basic demographic data:

```{r, echo=FALSE}
par(mfrow=c(2,2))
hist(la.census$white, main="White % Population")
hist(la.census$rate.poverty, main="% in Poverty")
hist(la.census$median.income, main="Median Income")
hist(la.census$population, main="Population")
```





```{r, echo=FALSE, warning=FALSE}
# Number of census tracts to sample
n <- 2
search.text <- 'Starbucks Coffee'

# Loading the shape file
# LA.shapefile <- readOGR(dsn="los_angeles/", 
#                         layer="eGIS_Demographic.EGIS", 
#                        verbose=FALSE) %>%
#  spTransform(CRS("+proj=longlat +ellps=WGS84"))

# LA.data <- LA.shapefile@data %>% tbl_df()

# I wasn't able to get this to work on my R installation, but Albert Kim was
# able to do so and save it as a data frame.
# LA.map <- fortify(LA.shapefile, region='GEOID10') %>% tbl_df()
load('LA.RData') # saved as LA.map

# Subset shapefile to tracts we want to look at
LA.map %<>% 
  inner_join(la.census, by=c('id' = 'Geo_FIPS')) %>%
  filter(lat > 33.5)
```

Now that we have a selection of census tracts to examine, we need to find how
many Starbucks locations are nearby each. To get all the relevant locations in
the area, we can do a series of searches on Google around specially chosen
points. We can do this with 24 radar searches with radii of 13 kilometers. The
maximum radius is 50km, but this increases the likelihood that we will miss
locations, for the API call only returns up to 200 locations at once.(The
function here to draw circles was adapted from code written by
Gregoire Vincke, in a 
[Stack Overflow answer](http://stackoverflow.com/a/29133886/4645559).)
```{r}
makeCircle <- function(LonDec, LatDec, Km, group) {#Corrected function
    #LatDec = latitude in decimal degrees of the center of the circle
    #LonDec = longitude in decimal degrees
    #Km = radius of the circle in kilometers
    ER <- 6371 #Mean Earth radius in kilometers. Change this to 3959 and you will have your function working in miles.
    AngDeg <- seq(1:360) #angles in degrees 
    Lat1Rad <- LatDec*(pi/180)#Latitude of the center of the circle in radians
    Lon1Rad <- LonDec*(pi/180)#Longitude of the center of the circle in radians
    AngRad <- AngDeg*(pi/180)#angles in radians
    Lat2Rad <-asin(sin(Lat1Rad)*cos(Km/ER)+cos(Lat1Rad)*sin(Km/ER)*cos(AngRad)) #Latitude of each point of the circle rearding to angle in radians
    Lon2Rad <- Lon1Rad+atan2(sin(AngRad)*sin(Km/ER)*cos(Lat1Rad),cos(Km/ER)-sin(Lat1Rad)*sin(Lat2Rad))#Longitude of each point of the circle rearding to angle in radians
    Lat2Deg <- Lat2Rad*(180/pi)#Latitude of each point of the circle rearding to angle in degrees (conversion of radians to degrees deg = rad*(180/pi) )
    Lon2Deg <- Lon2Rad*(180/pi)#Longitude of each point of the circle rearding to angle in degrees (conversion of radians to degrees deg = rad*(180/pi) )
    # output dataframe of locations
    return(data_frame(long = Lon2Deg, lat = Lat2Deg, group = group))
}

LA.plot <- ggplot() +
  geom_polygon(aes(x = long, y = lat, group=group), data=LA.map)

search.centers <- data_frame(
  long = c(seq(-118.6, -117.75, length.out=6),
           seq(-118.6, -117.74, length.out=5),
           seq(-118.85, -117.75, length.out=7),
           seq(-118.4, -117.85, length.out = 4),
           seq(-118.31, -118.13, length.out = 2)
           ),
  lat = c(rep(34.41, 6),
          rep(34.24, 5),
          rep(34.085, 7),
          rep(33.95, 4),
          rep(33.78, 2)))

circles <- data_frame(long = numeric(), lat = numeric(),
           group = integer())

for (i in 1:nrow(search.centers)) {
  long <- search.centers$long[i]
  lat <- search.centers$lat[i]
  radius <- 13 #km
  circles %<>% bind_rows(makeCircle(long, lat, radius, i))
}

LA.plot + 
  geom_point(aes(x = long, y = lat), data=search.centers,
             color = 'red')  + 
  geom_polygon(aes(x = long, y = lat, group=group), data=circles,
               color='red', fill = 'red', linetype='dotted',
               alpha=0.2) + 
  labs(title = "Radar Search Locations")


```



```{r}
# Define function to get nearby locations
getLocations <- function(x, y, query, radius=10000) {
  # Uses Google Places to find all locations near a place.
  # Remember we want to over shoot, and then count those that
  # are actually near the borders of the 
  #
  # Args: 
  #  x: the lattitude of the center from which to search
  #  y: the longitude of the center from which to search
  #  radius: the radius of the search, in meters
  #  query: the name of the franchise to search for
  #
  # Returns:
  #  A dataframe of locations.
  
  # First, construct the query URL
  gplaces.key <- readLines('Google_API_key.txt')
  url <- 'https://maps.googleapis.com/maps/api/place/radarsearch/json?'
  url %<>% paste('key=', gplaces.key, '&', sep='')
  url %<>% paste('location=', as.character(x), ',',
                 as.character(y), '&', sep='')
  url %<>% paste('radius=', as.character(radius), '&', sep='')
  query %<>% str_replace(' ', '+')
  url %<>% paste('keyword=', query, sep='')
  
  data <- url %>% getURL() %>% fromJSON()
  
  if (data$status != "ZERO_RESULTS") {
    
    data %<>% .$results %>% as.data.frame()
    
    output <- data_frame(place_id = data$place_id,
                         lat = data$geometry$location$lat,
                         long = data$geometry$location$lng)
    return(output) 
    } else {
      return(data_frame(place_id = character(),
                        lat = numeric(),
                        long = numeric()))
      }
  }

# test <- getLocations(34.0429419, -118.2657636, 'starbucks coffee')

search.text <- "Starbucks Coffee"

#locations <- data_frame(place_id = character(),
#                        lat = numeric(),
#                        long = numeric())

#for (i in 1:nrow(search.centers)) {
#  long <- search.centers$long[i]
#  lat <- search.centers$lat[i]
#  
#  new.locations <- getLocations(lat,
#                                long,
#                                search.text)
#  locations %<>% union(new.locations)
#}
  
# Saved Locations
#save(locations, file='sblocations.RData')
load('sblocations.RData')

ggplot() +
  geom_polygon(data = LA.map,
               aes(x=long, y=lat, group=group)) +
  geom_point(data = locations,
             aes(x = long, y = lat),
             color = 'green') + 
  coord_map() +
  theme_bw() + 
  labs(title = "Locations of Starbucks in Los Angeles County")

```

Notice there are some areas with no locations. To the north is Angeles National
Forest, and the western stretch is Santa Monica Mountains Recreational Area. In
some areas, that are likely less populated, the locations seem to align with
whatever freeways are nearby.

Now we need to calculate how many Starbuck's locations are near each census
tract.

```{r}
countLocations <- function(polygon, locations, radius=2) {
  # Counts the number of locations that are either inside the polygon, or are 
  # within the given radius of a border.
  #
  # Args:
  #  polygon: a dataframe of edges of the polygon
  #  locations: a dataframe of the locations, which is returned by getLocations
  #  radius: a radius in km to be the max valide distance from accessible location
  #
  # Returns: 
  #  An integer indicating how many locations are near the polygon
  
  # First, check if the point is actually inside the polygon
  output <- point.in.polygon(locations$long, locations$lat, 
                             polygon$long, polygon$lat)
  
  # If that doesn't work, check whether they are within a certain radius of the
  # edges of of polygon.
  
  # Convert radius to long and lat radius
  earth.radius <- 6371 # km
  deg.to.rad <- pi/180
  rad.to.deg <- 180/pi
  approx.lat <- mean(polygon$lat) # lat at census tract
  radius.lat <- ( radius/ earth.radius) * rad.to.deg
  radius.at.lat <- earth.radius * cos(approx.lat * deg.to.rad)
  radius.long <- (radius / radius.at.lat) * rad.to.deg
  
  for (i in 1:nrow(locations)) {
    if (output[i] == FALSE) {
      location <- locations[i,]
      long <- location$long
      lat <- location$lat
      
      # Check if there is even a chance of intersection
      polygon.long.range <- range(polygon$long) + c(-1,1) * radius.long
      polygon.lat.range <- range(polygon$lat) + c(-1, 1) * radius.lat
      in.int <- function(x,y) y[1] <= x & x <= y[2]
      nearby <- (in.int(long, polygon.long.range) &
                   in.int(lat, polygon.lat.range))
      
      if (nearby) {
        # Then make a circle and check all the points
        circle.points <- makeCircle(long, lat, radius, 1)
        # Now we check if the circle and polygon over lap. Looks overly
        # complicated? It is. Thanks a lot sp package...
        circle <- cbind(circle.points$long, circle.points$lat) %>%
          Polygon() %>%
          list() %>% Polygons(1) %>%
          list() %>% SpatialPolygons()
        tract <- cbind(polygon$long, polygon$lat) %>%
          Polygon() %>%
          list() %>% Polygons(2) %>%
          list() %>% SpatialPolygons()
        overlaps <- gOverlaps(circle, tract)
        contains <- gContains(circle, tract) | gContains(tract, circle)
        output[i] <- overlaps | contains
        #print(gOverlaps(circle, tract))
        }
      
      }
    }
  
  output %>% sum() %>% return()
  }
  

la.census$sb.count = numeric(length = nrow(la.census))  


# Single thread version
#  for (i in 1:(nrow(la.census)) ) {
#    row <- la.census[i,]
#    FIPS <- row$Geo_FIPS
#    polygon <- LA.map %>% filter(id == FIPS)
#    la.census[i,]$sb.count <- countLocations(polygon, locations)
#  }

getLocationCount <- function (row.iter) {
  obs <- la.census[row.iter,]
  FIPS <- obs$Geo_FIPS
  polygon <- LA.map %>% filter(id == FIPS)
  countLocations(polygon, locations, radius=2)
  }


loc.count.result <- foreach(i=1:nrow(la.census), .combine=c) %dopar%
  getLocationCount(i)


la.census$sb.count <- loc.count.result

qplot(x = la.census$sb.count, title="Histogram of # of Starbuck's")
```

TO DO:
* Get Histogram of starbucks
* Determine distribution of Starbucks
* For each variable, do Monte Carlo simlulation to determine whether they are
  correlated. Make each variable into a categorical variable.



